{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58d5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5cd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear(n=100):\n",
    "    pts = np.random.uniform(0, 1, (n, 2))\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for pt in pts:\n",
    "        inputs.append([pt[0], pt[1]])\n",
    "        if pt[0] > pt[1]:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return np.array(inputs), np.array(labels).reshape(n, 1)\n",
    "\n",
    "def generate_XOR_easy(n=11):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    step = 1/(n-1)\n",
    "    for i in range(n):\n",
    "        inputs.append([step*i, step*i])\n",
    "        labels.append(0)\n",
    "        \n",
    "        if i == int((n-1)/2):\n",
    "            continue\n",
    "        \n",
    "        inputs.append([step*i, 1 - step*i])\n",
    "        labels.append(1)\n",
    "\n",
    "    return np.array(inputs), np.array(labels).reshape(n*2 - 1,1)\n",
    "\n",
    "def show_result(x,y,pred_y):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Ground Truth\",fontsize=18)\n",
    "    for i in range(x.shape[0]):\n",
    "        if y[i] == 0:\n",
    "            plt.plot(x[i][0],x[i][1],'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0],x[i][1],'bo')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Predict Result\",fontsize=18)\n",
    "    for i in range(x.shape[0]):\n",
    "        if pred_y[i] == 0:\n",
    "            plt.plot(x[i][0],x[i][1],'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0],x[i][1],'bo')\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "#def derivative_sigmoid(x):\n",
    "#    return np.multiply(sigmoid(x), 1.0 - sigmoid(x))\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return np.multiply(x, 1.0 - x)\n",
    "\n",
    "def relu(X):\n",
    "    X = np.copy(X)\n",
    "    for i in range(X.shape[1]):\n",
    "        X[0][i] = max(0.0, X[0][i])\n",
    "    return X\n",
    "\n",
    "def derivative_relu(X):\n",
    "    d_X = np.copy(X)\n",
    "    for i in range(d_X.shape[1]):\n",
    "        if(d_X[0][i]>0.0):\n",
    "            d_X[0][i] = 1.0\n",
    "        else:\n",
    "            d_X[0][i] = 0.0\n",
    "    return d_X\n",
    "\n",
    "def lrelu(X,a=0.01):\n",
    "    X = np.copy(X)\n",
    "    for i in range(X.shape[1]):\n",
    "        if(X[0][i]<0.0):\n",
    "            X[0][i] *= a\n",
    "\n",
    "    return X\n",
    "\n",
    "def derivative_lrelu(X,a=0.01):\n",
    "    d_X = np.copy(X)\n",
    "    for i in range(d_X.shape[1]):\n",
    "        if(d_X[0][i]>0.0):\n",
    "            d_X[0][i] = 1.0\n",
    "        else:\n",
    "            d_X[0][i] = a\n",
    "    return d_X\n",
    "\n",
    "def MSE_loss(y, y_hat):\n",
    "    return np.mean((y - y_hat)**2)\n",
    "\n",
    "def derivative_MSE_loss(y, y_hat):\n",
    "    return (y - y_hat)*(2/y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec667817",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = generate_linear()\n",
    "x2, y2 = generate_XOR_easy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d9095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear:\n",
    "    def __init__(self,in_size,out_size,act):\n",
    "        self.prev_X = np.zeros((1,in_size))\n",
    "        self.prev_Y = np.zeros((1,out_size))\n",
    "        self.prev_sig = np.zeros((1,out_size))\n",
    "        self.W = np.random.uniform(0,1,(in_size,out_size))\n",
    "        self.W_grad = np.zeros((in_size,out_size))\n",
    "        self.backward_gradient = np.zeros(out_size)\n",
    "        self.act = act\n",
    "\n",
    "        \n",
    "\n",
    "    #calculate the value W*X, and store X for gradient calculation\n",
    "    def forward(self,X):\n",
    "        #self.prev_X = X\n",
    "        self.prev_X = np.copy(X)\n",
    "        self.prev_Y = np.matmul(X,self.W)\n",
    "\n",
    "        if(self.act == 'sigmoid'):\n",
    "            self.prev_sig = sigmoid(self.prev_Y)\n",
    "            #return np.copy(self.prev_sig)\n",
    "            return self.prev_sig\n",
    "        elif(self.act == 'relu'):\n",
    "            return relu(self.prev_Y)\n",
    "        elif(self.act == 'lrelu'):\n",
    "            return lrelu(self.prev_Y)\n",
    "        elif(self.act == 'no'):\n",
    "            return self.prev_Y\n",
    "            #return np.copy(self.prev_Y)\n",
    "\n",
    "\n",
    "    def backword(self,derivative):\n",
    "\n",
    "        if(self.act == 'sigmoid'):\n",
    "       \n",
    "            self.backward_gradient=np.copy(derivative_sigmoid(self.prev_sig))\n",
    "            for i in range(derivative.shape[1]):\n",
    "                self.backward_gradient[0][i] *= derivative[0][i]\n",
    "        elif(self.act == 'relu'):\n",
    "            self.backward_gradient=np.copy(derivative_relu(self.prev_Y))\n",
    "            for i in range(derivative.shape[1]):\n",
    "                self.backward_gradient[0][i] *= derivative[0][i]\n",
    "            \n",
    "        elif(self.act == 'lrelu'):\n",
    "            self.backward_gradient=np.copy(derivative_lrelu(self.prev_Y))\n",
    "            for i in range(derivative.shape[1]):\n",
    "                self.backward_gradient[0][i] *= derivative[0][i]\n",
    "            \n",
    "        elif(self.act == 'no'):\n",
    "            self.backward_gradient = np.copy(derivative)\n",
    "\n",
    "        return np.matmul(self.backward_gradient,self.W.T)\n",
    "\n",
    "    def get_weights(self,learning_rate):\n",
    "        for i in range(self.prev_X.shape[1]):\n",
    "            for j in range(self.prev_Y.shape[1]):\n",
    "                self.W_grad[i][j] -= learning_rate*self.prev_X[0][i]*self.backward_gradient[0][j]\n",
    "\n",
    "    def update_weights(self,batch_size):\n",
    "\n",
    "        self.W += self.W_grad/batch_size\n",
    "        self.W_grad[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a2d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_NN:\n",
    "    def __init__(self,learning_rate = 1):\n",
    "        self.layers = []\n",
    "        self.learning_rate = learning_rate\n",
    "    def forward(self,X):\n",
    "        in_data = X\n",
    "        for l in self.layers:\n",
    "            in_data = l.forward(in_data)\n",
    "        return in_data\n",
    "    def backword(self,derivative):\n",
    "        back_dev = derivative\n",
    "        for l in reversed(self.layers):\n",
    "            back_dev = l.backword(back_dev)\n",
    "            l.get_weights(self.learning_rate)\n",
    "        #return back_dev\n",
    "        \n",
    "    def add_linear_layer(self,in_size,out_size,act):\n",
    "        l = linear(in_size,out_size,act)\n",
    "        self.layers.append(l)\n",
    "        \n",
    "    def update_weights(self,batch_size):\n",
    "        for l in self.layers:\n",
    "            l.update_weights(batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae7864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "linear_nn = My_NN()\n",
    "linear_nn.add_linear_layer(in_size = 2, out_size = 2, act = 'relu')\n",
    "linear_nn.add_linear_layer(in_size = 2,out_size = 1, act = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61827171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  MSE loss = 0.28689482357785656\n",
      "Epoch 100:  MSE loss = 0.08055694547609728\n",
      "Epoch 200:  MSE loss = 0.037134710967118324\n",
      "Epoch 300:  MSE loss = 0.026927679862646915\n",
      "Epoch 400:  MSE loss = 0.02216558910691016\n"
     ]
    }
   ],
   "source": [
    "log_period = 100\n",
    "batch_size = len(x1)\n",
    "epoch_num = 1000\n",
    "\n",
    "for i in range(epoch_num):\n",
    "    loss = 0\n",
    "    for data,label in zip(x1,y1):\n",
    "        ret = linear_nn.forward(np.array(data).reshape(1,2))       \n",
    "        loss += MSE_loss(ret,label)    \n",
    "        linear_nn.backword(derivative_MSE_loss(ret,label))\n",
    "        \n",
    "    loss /= batch_size\n",
    "    linear_nn.update_weights(batch_size)\n",
    "    if(i%log_period == 0):\n",
    "        print(f\"Epoch {i}:  MSE loss = {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97741b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "linear_result = []\n",
    "for data,label in zip(x1,y1):\n",
    "    ret = linear_nn.forward(np.array(data).reshape(1,2))     \n",
    "    linear_result.append(1 if ret>0.5 else 0)\n",
    "    if(ret>0.5 and label==1):\n",
    "        tp += 1\n",
    "    elif(ret<=0.5 and label==0):\n",
    "        tn += 1\n",
    "    elif(ret<0.5 and label==1):\n",
    "        fn += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "print(\"Confusion Matrix of Linear Problem:\")\n",
    "print(f\"TP:{tp}\")\n",
    "print(f\"TN:{tn}\")\n",
    "print(f\"FP:{fp}\")\n",
    "print(f\"FN:{fn}\")\n",
    "print(f\"Accuracy:{(tp+tn)/len(x1)}\")\n",
    "print(f\"Precision:{tp/(tp+fp)}\")\n",
    "show_result(x1,y1,linear_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "xor_nn = My_NN()\n",
    "xor_nn.add_linear_layer(in_size = 2, out_size = 6, act = 'lrelu')\n",
    "xor_nn.add_linear_layer(in_size = 6,out_size = 1, act = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_period = 100\n",
    "batch_size = len(x2)\n",
    "epoch_num = 1000\n",
    "\n",
    "for i in range(epoch_num):\n",
    "    loss = 0\n",
    "    for data,label in zip(x2,y2):\n",
    "        ret = xor_nn.forward(np.array(data).reshape(1,2))       \n",
    "        loss += MSE_loss(ret,label)    \n",
    "        xor_nn.backword(derivative_MSE_loss(ret,label))\n",
    "        \n",
    "    loss /= batch_size\n",
    "    xor_nn.update_weights(batch_size)\n",
    "    if(i%log_period == 0):\n",
    "        print(f\"Epoch {i}:  MSE loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c336e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "xor_result = []\n",
    "for data,label in zip(x2,y2):\n",
    "    ret = xor_nn.forward(np.array(data).reshape(1,2))     \n",
    "    xor_result.append(1 if ret>0.5 else 0)\n",
    "    if(ret>0.5 and label==1):\n",
    "        tp += 1\n",
    "    elif(ret<=0.5 and label==0):\n",
    "        tn += 1\n",
    "    elif(ret<0.5 and label==1):\n",
    "        fn += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "print(\"Confusion Matrix of Linear Problem:\")\n",
    "print(f\"TP:{tp}\")\n",
    "print(f\"TN:{tn}\")\n",
    "print(f\"FP:{fp}\")\n",
    "print(f\"FN:{fn}\")\n",
    "print(f\"Accuracy:{(tp+tn)/len(x2)}\")\n",
    "print(f\"Precision:{tp/(tp+fp)}\")\n",
    "show_result(x2,y2,xor_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
